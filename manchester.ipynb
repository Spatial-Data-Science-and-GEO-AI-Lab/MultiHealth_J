{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system packages\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import fiona\n",
    "from collections import Counter\n",
    "\n",
    "# non-geo numeric packages\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "import pandas as pd\n",
    "\n",
    "# network and OSM packages\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "city_geo = ox.geocoder.geocode_to_gdf\n",
    "\n",
    "# Earth engine packages\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# General geo-packages\n",
    "from rasterstats import zonal_stats\n",
    "from pyproj import CRS\n",
    "import libpysal\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, MultiLineString, LineString, Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading latest dataframe\n",
    "#popgridmanchester = gpd.read_file('popgridmanchester2.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popgridmanchester = gpd.read_file('popgridmanchester3.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEE auth/initialisation, loading health outcome data, extracting population grid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and Initialize Google Earth Engine\n",
    "#ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided dataset including health outcomes\n",
    "data = gpd.read_file(\"/Users/Julian/Desktop/Julian/PSY/Thesis/data/Greater_Manchester_NH_GIS.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health outcome only\n",
    "data_health = data[['geometry','lsoa11cd','UNID','lsoa11nm','ID','lon','lat','Yrpotlife','Comilldis','Obes_Per_Obesprev_y15', 'Asthma_Per_Asthmaprev_y17', 'heart_Per_heartdiseaseprev_y17', 'Stroke_Per_Strokeprev_y17', 'Cancer_Per_cancerPrev_y17', 'samhi_index2019', 'prop_ibesa', 'est_qof_dep', 'antidep_rate']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify cities using the excel files with the cities and iso's\n",
    "\n",
    "# Extract iso-3166 country codes\n",
    "iso = pd.read_excel('/Users/Julian/Desktop/Julian/PSY/Thesis/data/iso_countries.xlsx')\n",
    "\n",
    "# Extract cities list\n",
    "cities = pd.read_excel('/Users/Julian/Desktop/Julian/PSY/Thesis/data/cities.xlsx') # all cities\n",
    "\n",
    "# 'cities_adj' serves by default as city-input for functions\n",
    "cities_adj = cities[cities['City'].isin(['Manchester'])]\n",
    "cities_adj = cities_adj.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract worldpop data from GEE of the cities\n",
    "def gee_worldpop_extract (city_file, iso, save_path = None):\n",
    "    \n",
    "    cities = city_file\n",
    "    \n",
    "    # Get included city areas\n",
    "    OSM_incl = [cities[cities['City'] == city]['OSM_area'].tolist()[0].rsplit(', ') for city in cities['City'].tolist()]\n",
    "\n",
    "    # Get the city geoms\n",
    "    obj = [city_geo(city).dissolve()['geometry'].tolist()[0] for city in OSM_incl]\n",
    "    \n",
    "    # Get the city countries\n",
    "    obj_displ = [city_geo(city).dissolve()['display_name'].tolist()[0].rsplit(', ')[-1]for city in OSM_incl]\n",
    "    obj_displ = np.where(pd.Series(obj_displ).str.contains(\"Ivoire\"),\"CIte dIvoire\",obj_displ)\n",
    "\n",
    "    # Get the country's iso-code\n",
    "    iso_list = [iso[iso['name'] == ob]['alpha3'].tolist()[0] for ob in obj_displ]\n",
    "\n",
    "    # Based on the iso-code return the worldpop 2020\n",
    "    ee_worldpop = [ee.ImageCollection(\"WorldPop/GP/100m/pop\")\\\n",
    "        .filter(ee.Filter.date('2020'))\\\n",
    "        .filter(ee.Filter.inList('country', [io])).first() for io in iso_list]\n",
    "\n",
    "    # Clip the countries with the city geoms.\n",
    "    clipped = [ee_worldpop[i].clip(shapely.geometry.mapping(obj[i])) for i in range(0,len(obj))]\n",
    "\n",
    "    # Create path if non-existent\n",
    "    if save_path == None:\n",
    "        path = ''\n",
    "    else:\n",
    "        path = save_path\n",
    "        if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "\n",
    "    # Export as TIFF file.\n",
    "    # Stored in form path + USA_Los Angeles_2020.tif\n",
    "    filenames = [path+iso_list[i]+'_'+cities['City'][i]+'_2020.tif' for i in range(len(obj))]\n",
    "    [geemap.ee_export_image(clipped[i], filename = filenames[i]) for i in range(0,len(obj))]\n",
    "    return(filenames)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now grid based on the 27700 CRS\n",
    "\n",
    "# function to create population grids of the cities\n",
    "def city_grids_format(city_grids, cities_area, grid_size = 100):\n",
    "    start_time = time.time()\n",
    "    grids = []\n",
    "    print(str(grid_size) + 'm resolution grids extraction')\n",
    "    for i in range(len(city_grids)):\n",
    "        \n",
    "        # Open the raster file\n",
    "        with rasterio.open(city_grids[i]) as src:\n",
    "            band= src.read() # the population values\n",
    "            aff = src.transform # the raster bounds and size (affine)\n",
    "        \n",
    "        # Get the rowwise arrays, get a 2D dataframe\n",
    "        grid = pd.DataFrame()\n",
    "        for b in enumerate(band[0]):\n",
    "            grid = pd.concat([grid, pd.Series(b[1],name=b[0])],axis=1)\n",
    "        grid= grid.unstack().reset_index()\n",
    "        \n",
    "        # Unstack df to columns\n",
    "        grid.columns = ['row','col','value']\n",
    "        grid['minx'] = aff[2]+aff[0]*grid['col']\n",
    "        grid['miny'] = aff[5]+aff[4]*grid['row']\n",
    "        grid['maxx'] = aff[2]+aff[0]*grid['col']+aff[0]\n",
    "        grid['maxy'] = aff[5]+aff[4]*grid['row']+aff[4]\n",
    "        \n",
    "        # Create polygon from affine bounds and row/col indices\n",
    "        grid['geometry'] = [Polygon([(grid.minx[i],grid.miny[i]),\n",
    "                                   (grid.maxx[i],grid.miny[i]),\n",
    "                                   (grid.maxx[i],grid.maxy[i]),\n",
    "                                   (grid.minx[i],grid.maxy[i])])\\\n",
    "                          for i in range(len(grid))]\n",
    "        \n",
    "        # Set the df as geo-df\n",
    "        grid = gpd.GeoDataFrame(grid, crs = 27700) \n",
    "\n",
    "        # Get dissolvement_key for dissolvement. \n",
    "        grid['row3'] = np.floor(grid['row']/(grid_size/100)).astype(int)\n",
    "        grid['col3'] = np.floor(grid['col']/(grid_size/100)).astype(int)\n",
    "        grid['dissolve_key'] = grid['row3'].astype(str) +'-'+ grid['col3'].astype(str)\n",
    "        \n",
    "        # Define a city's OSM area as Polygon.\n",
    "        geo_ls = gpd.GeoSeries(city_geo(cities_area[i].split(', ')).dissolve().geometry)\n",
    "        geo_ls = geo_ls.to_crs(\"EPSG:27700\")\n",
    "        \n",
    "        # Intersect grids with the city boundary Polygon.\n",
    "        insec = grid.intersection(geo_ls.tolist()[0])\n",
    "        \n",
    "        # Exclude grids outside the specified city boundaries\n",
    "        insec = insec[insec.area > 0]\n",
    "        \n",
    "        # Join in other information.\n",
    "        insec = gpd.GeoDataFrame(geometry = insec, crs = 27700).join(grid.loc[:, grid.columns != 'geometry'])\n",
    "        \n",
    "        # Dissolve into block by block grids\n",
    "        popgrid = insec[['dissolve_key','geometry','row3','col3']].dissolve('dissolve_key')\n",
    "        \n",
    "        # Get those grids populations and area, only full blocks\n",
    "        popgrid['population'] = round(insec.groupby('dissolve_key')['value'].sum()).astype(int)\n",
    "        #popgrid['area_m'] = round(gpd.GeoSeries(popgrid['geometry'], crs = 27700).to_crs(3043).area).astype(int)\n",
    "        popgrid = popgrid[popgrid['population'] >= 0]\n",
    "        #popgrid = popgrid[popgrid['area_m'] / popgrid['area_m'].max() > 0.95]\n",
    "\n",
    "        # Get centroids and coords\n",
    "        popgrid['centroid'] = popgrid['geometry'].centroid\n",
    "        #popgrid['centroid_m'] = gpd.GeoSeries(popgrid['centroid'], crs = '27700').to_crs(3043)\n",
    "        popgrid['grid_lon'] = popgrid['centroid'].x\n",
    "        popgrid['grid_lat'] = popgrid['centroid'].y\n",
    "        popgrid = popgrid.reset_index()\n",
    "\n",
    "        minx = popgrid.bounds['minx']\n",
    "        maxx = popgrid.bounds['maxx']\n",
    "        miny = popgrid.bounds['miny']\n",
    "        maxy = popgrid.bounds['maxy']\n",
    "\n",
    "        # Some geometries result in a multipolygon when dissolving (like i.e. 0.05 meters), coords error.\n",
    "        # Therefore recreate the polygon.\n",
    "        Poly = []\n",
    "        for k in range(len(popgrid)):\n",
    "            Poly.append(Polygon([(minx[k],maxy[k]),(maxx[k],maxy[k]),(maxx[k],miny[k]),(minx[k],miny[k])]))\n",
    "        popgrid['geometry'] = Poly\n",
    "\n",
    "        grids.append(popgrid)\n",
    "\n",
    "        print(city_grids[i].rsplit('_')[3], round((time.time() - start_time)/60,2),'mns')\n",
    "    return(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# In essence, we use Google Earth Engine to extract a country's grid raster and clip it with the city's preferred OSM area\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj, iso, '/Users/Julian/Desktop/Julian/PSY/Thesis/data/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprojecting the population TIF with the code snippit from the rasterio documentation\n",
    "\n",
    "# destination CRS\n",
    "dst_crs = 'EPSG:27700'\n",
    "\n",
    "# open the source GeoTIFF file and transform the dimensions and CRS\n",
    "with rasterio.open('/Users/Julian/Desktop/Julian/PSY/Thesis/data/GEE_city_grids/GBR_Manchester_2020.tif') as src:\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "    # save the new destination GeoTIFF file with the adjusted dimensions and CRS\n",
    "    with rasterio.open('/Users/Julian/Desktop/Julian/PSY/Thesis/data/GEE_city_grids/GBR_Manchester_2020.tif', 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(src, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the population grid\n",
    "\n",
    "# clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print(' ')\n",
    "\n",
    "# save the dataframe\n",
    "popgridmanchester = population_grids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding grid_lat/lon from 4326 for OSMNX network retrieval\n",
    "popgridmanchester = popgridmanchester.to_crs(\"EPSG:4326\")\n",
    "popgridmanchester['centroid'] = popgridmanchester.geometry.centroid\n",
    "popgridmanchester['grid_lon_4326'] = popgridmanchester['centroid'].x\n",
    "popgridmanchester['grid_lat_4326'] = popgridmanchester['centroid'].y\n",
    "popgridmanchester = popgridmanchester.to_crs(\"EPSG:27700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove centroid to be able to save it as a GPKG\n",
    "popgridmanchester = popgridmanchester.drop(columns=['centroid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as gkpg file\n",
    "popgridmanchester.to_file(\"popgridmanchester3.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open gkpg file\n",
    "#popgridmanchester = gpd.read_file(\"popgridmanchester.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data points such as bus stops and restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Greater Manchester polygon using OSM\n",
    "manchester_osm = city_geo('Greater Manchester')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using OSM to extract data points\n",
    "\n",
    "# specifying correct ESPG\n",
    "epsg = \"EPSG:27700\"\n",
    "\n",
    "# specifying the Greater Manchester polygon\n",
    "manchester_poly = manchester_osm.geometry.unary_union\n",
    "\n",
    "# extracting bus stops\n",
    "bus_stops = ox.geometries_from_polygon(manchester_poly, tags={'highway': 'bus_stop'})\n",
    "bus_stops = bus_stops.to_crs(epsg)\n",
    "bus_stops = bus_stops[['geometry']]\n",
    "bus_stops = bus_stops.reset_index()\n",
    "\n",
    "# extracting restaurants\n",
    "restaurants = ox.geometries_from_polygon(manchester_poly, tags={'amenity': ['bar', 'pub', 'restaurant', 'cafe']})\n",
    "restaurants = restaurants.to_crs(epsg)\n",
    "restaurants = restaurants[['geometry']]\n",
    "restaurants = restaurants.reset_index()\n",
    "\n",
    "# extracting daily shops\n",
    "shops = ox.geometries_from_polygon(manchester_poly, tags={'shop': ['department_store', 'supermarket', 'convenience']})\n",
    "shops.to_crs(epsg)\n",
    "shops = shops[['geometry']]\n",
    "shops = shops.reset_index()\n",
    "\n",
    "# extracting cyclelanes\n",
    "cycleways = ox.geometries_from_polygon(manchester_poly, tags={'cycleway': True, 'highway':'cycleway'})\n",
    "cycleways.to_crs(epsg)\n",
    "cycleways_c = cycleways[['geometry']]\n",
    "cycleways_c = cycleways_c.reset_index()\n",
    "\n",
    "#Create union out of all geometry extracted\n",
    "temp_list = []\n",
    "\n",
    "for index, x in cycleways_c.iterrows():\n",
    "    temp_list.append(x.geometry)\n",
    "\n",
    "series = gpd.GeoSeries(temp_list)\n",
    "\n",
    "# convert to gdf and export as gpkg\n",
    "cycleways_gdf = gpd.GeoDataFrame(geometry=gpd.GeoSeries(series))\n",
    "#cycleways_gdf.to_file(\"cycleways.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population sum of each grid bufferzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bufferzone dataframe from population grid dataframe geometries\n",
    "buffer_gdf = popgridmanchester.copy()\n",
    "buffer_gdf['centroid'] = buffer_gdf['geometry'].centroid\n",
    "buffer_gdf['buffer'] = buffer_gdf['centroid'].buffer(500)\n",
    "buffer_gdf = buffer_gdf['buffer']\n",
    "buffer_gdf = gpd.GeoDataFrame(buffer_gdf, geometry='buffer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersect with bounds of the OSM city area so buffers don't extent beyond city borders\n",
    "manpoly = city_geo('Greater Manchester').dissolve()['geometry']\n",
    "manpoly = manpoly.to_crs(\"EPSG:27700\")\n",
    "bufferintersect = buffer_gdf.intersection(manpoly.geometry[0])\n",
    "#gridpoly = popgridmanchester.dissolve()['geometry']\n",
    "#bufferintersect = buffer_gdf.intersection(gridpoly.geometry[0])\n",
    "\n",
    "# I tried intersecting with a dissolved polygon from the population grid intstead of with a dissolved\n",
    "# polygon from the OSM city area, because the population grid polygon contains small areas with no data\n",
    "# that would then not be present within the buffers. Using rasterstats with that intersection would then \n",
    "# minimize the amount of missing data set to a negative number. This took too much time however.\n",
    "# Might try again later.\n",
    "\n",
    "# convert to gdf and save to gpkg\n",
    "bufferintersect_gdf = gpd.GeoDataFrame(bufferintersect)\n",
    "bufferintersect_gdf = bufferintersect_gdf.rename(columns={0: \"geometry\"})\n",
    "bufferintersect_gdf.geometry = bufferintersect_gdf['geometry']\n",
    "bufferintersect_gdf.to_file(\"bufferintersect_gdf.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the buffergintersect_gdf file\n",
    "bufferintersect_gdf = gpd.read_file(\"bufferintersect_gdf.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parts from the buffer that do not intersect with the population grid, so the parts\n",
    "# that have no data.\n",
    "start_time = time.time()\n",
    "\n",
    "bufferintersect_gdf['savedindex'] = bufferintersect_gdf.index\n",
    "difference_gdf = bufferintersect_gdf.overlay(popgridmanchester, how='difference')['savedindex']\n",
    "\n",
    "# filter the buffer gdf of these difference parts\n",
    "buffer_gdf_filtered = bufferintersect_gdf[~bufferintersect_gdf.savedindex.isin(difference_gdf.geometry)]\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popgridpoly = popgridmanchester['geometry']\n",
    "popgridpoly = gpd.GeoDataFrame(popgridpoly)\n",
    "popgridpoly = popgridpoly.dissolve()\n",
    "test = popgridpoly.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# use the reprojected population TIF with CRS 27700\n",
    "with rasterio.open('/Users/Julian/Desktop/Julian/PSY/Thesis/data/GEE_city_grids/GBR_Manchester_2020.tif') as src:\n",
    "    affine = src.transform\n",
    "    array = src.read(1)\n",
    "\n",
    "# get population sum statistic per bufferzone\n",
    "statistics = zonal_stats(bufferintersect_gdf2, array, affine=affine, stats=['sum'], nodata=0)\n",
    "    \n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the population sum per buffer from statistics\n",
    "# setting values to zero if negative\n",
    "population_sums = [stat['sum'] if (stat is not None and stat['sum'] >= 0) else 0 for stat in statistics]\n",
    "# converting to df to add to the population grid gdf\n",
    "population_sums_df = pd.DataFrame(population_sums, columns=['buffer_population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(population_sums_df==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(popgridmanchester['buffer_population']==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding population per buffer to buffer_gdf and then calculating density\n",
    "bufferintersect_gdf['buffer_area'] = bufferintersect_gdf['geometry'].area\n",
    "\n",
    "# adding both buffer population and buffer area columns to final gdf for other density calculations\n",
    "popgridmanchester['buffer_population'] = population_sums_df['buffer_population']\n",
    "popgridmanchester['buffer_area'] = bufferintersect_gdf['buffer_area']\n",
    "\n",
    "# calculating population density per buffer\n",
    "popgridmanchester['buffer_pop_density'] = popgridmanchester['buffer_population']/popgridmanchester['buffer_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to gpkg\n",
    "popgridmanchester.to_file(\"popgridmanchester3.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating three-way intersections per grid centroid street network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column with 0's for the three-way-intersections\n",
    "popgridmanchester['three-way-intersections'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "def calculate_intersections(row):\n",
    "    try:\n",
    "        G = ox.graph_from_point((row['grid_lat_4326'], row['grid_lon_4326']), dist=500, network_type='drive')\n",
    "        stats = ox.stats.count_streets_per_node(G)\n",
    "        return Counter(stats.values())[3]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "popgridmanchester['three-way-intersections'] = popgridmanchester.apply(calculate_intersections, axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file to gpkg\n",
    "#popgridmanchester.to_file('popgridmanchester2.gpkg', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test network \n",
    "G = ox.graph_from_point((popgridmanchester['grid_lat_4326'][453],\n",
    "                         popgridmanchester['grid_lon_4326'][453]),\n",
    "                        dist=500,\n",
    "                        network_type='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert network to gdf, create polygon from it to get area\n",
    "Gproj = ox.project_graph(G, to_crs=\"27700\")\n",
    "network_gdfs = ox.graph_to_gdfs(Gproj, nodes=True, edges=False)\n",
    "network_poly = network_gdfs.unary_union.convex_hull\n",
    "area = network_poly.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test network graph\n",
    "ox.plot_graph(Gproj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stats\n",
    "stats = ox.stats.basic_stats(Gproj, area=area)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-way-intersection density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the area of the bufferzone to get the intersection density\n",
    "popgridmanchester = popgridmanchester.to_crs(\"epsg:27700\")\n",
    "popgridmanchester['centroid'] = popgridmanchester['geometry'].centroid\n",
    "popgridmanchester['buffer'] = popgridmanchester['centroid'].buffer(500)\n",
    "popgridmanchester['buffer_area'] = popgridmanchester['buffer'].area\n",
    "popgridmanchester['buffer_area_km'] = popgridmanchester['buffer_area']/1000 # in kilometers\n",
    "# removing buffer and centroid again to save as gpkg\n",
    "popgridmanchester = popgridmanchester.drop(columns=['buffer', 'centroid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three-way-intersections divided by the area to get the density (also in square kilometers)\n",
    "popgridmanchester['three-way-intersection-density'] = popgridmanchester['three-way-intersections']/popgridmanchester['buffer_area']\n",
    "popgridmanchester['three-way-intersection-density_km'] = popgridmanchester['three-way-intersections']/popgridmanchester['buffer_area_km']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file to gpkg\n",
    "popgridmanchester.to_file('popgridmanchester2.gpkg', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "popgridmanchestertest = popgridmanchester[152000:152100]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def calculate_street_density(row):\n",
    "    try:\n",
    "        G = ox.graph_from_point((row['grid_lat_4326'], row['grid_lon_4326']), dist=500, network_type='drive')\n",
    "        stats = ox.stats.basic_stats(G, area=row['buffer_area'])\n",
    "        return stats['street_density_km']\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "popgridmanchestertest['street_density_km'] = popgridmanchestertest.apply(calculate_street_density, axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file to gpkg\n",
    "popgridmanchester.to_file('popgridmanchester2.gpkg', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Euclidean distance from grid centroids to nearest bus stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd() #Location where files will be saved\n",
    "c = \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating distance variabels to POIs\n",
    "\n",
    "bus_dist_list = []\n",
    "\n",
    "city = 'Greater Manchester'\n",
    "espg = 'EPSG:27700'\n",
    "city_path = directory + c + city\n",
    "\n",
    "# Load in Manchester grid data\n",
    "df = popgridmanchester.to_crs(espg)\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "\n",
    "# Load in bus stops\n",
    "busstop = gpd.read_file('bus_stops.gpkg').to_crs(espg)\n",
    "\n",
    "# Import points as gdf and loop through them\n",
    "for index, point in gdf.iterrows():\n",
    "    polygon_index = busstop.distance(point.geometry).sort_values().index[0]\n",
    "    nearest_bus = busstop.loc[polygon_index].geometry.centroid\n",
    "\n",
    "    # Extract coordinates of point\n",
    "    x, y = point.geometry.centroid.coords.xy\n",
    "    x = x[0]\n",
    "    y = y[0]\n",
    "        \n",
    "    # Extract coordinates of point\n",
    "    xx, yy = nearest_bus.xy\n",
    "    xx = xx[0]\n",
    "    yy = yy[0]\n",
    "\n",
    "    # Calculate shortest path\n",
    "    try:\n",
    "        ox.distance.euclidean_dist_vec(y, x, yy, xx)\n",
    "        \n",
    "    except:\n",
    "        s_path = 0\n",
    "        \n",
    "    else:\n",
    "        s_path = ox.distance.euclidean_dist_vec(y, x, yy, xx)\n",
    "\n",
    "    bus_dist_list.append(s_path)\n",
    "\n",
    "print(city + ' is done')\n",
    "\n",
    "df['dist_to_busstop'] = bus_dist_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_file('popgriddistance.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay with health outcome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match the crs to the health data crs\n",
    "popgridmanchester = popgridmanchester.to_crs(\"epsg:27700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overlay with the health outcome data\n",
    "overlay = data_health.overlay(popgridmanchester, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save overlay\n",
    "overlay.to_file(\"overlay.gpkg\", driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4fefabefd88c249e4f3218e5e8556846ec1b0550b646e9eb707687c9edb20c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
